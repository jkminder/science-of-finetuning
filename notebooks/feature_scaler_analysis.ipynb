{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "import torch as th\n",
    "\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch as th\n",
    "from pathlib import Path\n",
    "import json\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "BASE_DIR = Path(\"..\")\n",
    "\n",
    "CHECKPOINT_DIR = BASE_DIR / \"checkpoints\" / \"feature_scaler\"\n",
    "PLOTS_DIR = BASE_DIR / \"plots\"\n",
    "device = \"cuda\" if th.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_init_names = [\"S4-L13-mu0.0e+00-lr1e-02\", \"S42-L13-mu0.0e+00-lr1e-02\", \"S666-L13-mu0.0e+00-lr1e-02\"]\n",
    "zero_init_names = [\"S4-L13-mu0.0e+00-lr1e-02-ZeroInit\", \"S42-L13-mu0.0e+00-lr1e-02-ZeroInit\", \"S666-L13-mu0.0e+00-lr1e-02-ZeroInit\"]\n",
    "\n",
    "random_indices_names = [\"RandomIndicesL13-mu0.0e+00-lr1e-02\", \"RandomIndicesS4-L13-mu0.0e+00-lr1e-02\", \"RandomIndicesS666-L13-mu0.0e+00-lr1e-02\"]\n",
    "random_sources_names = [\"RandomSourceL13-mu0.0e+00-lr1e-02\", \"RandomSourceS4-L13-mu0.0e+00-lr1e-02\", \"RandomSourceS666-L13-mu0.0e+00-lr1e-02\"]\n",
    "full_scaler_name = \"L13-mu0.0e+00-lr1e-02-full\"\n",
    "\n",
    "base_model_fve = 0.83579\n",
    "\n",
    "def load_fve(name):\n",
    "    with open(CHECKPOINT_DIR / name / \"last_eval_logs.json\", \"r\") as f:\n",
    "        return json.load(f)[\"val/frac_variance_explained\"]\n",
    "one_init_fve = [load_fve(name) for name in one_init_names]\n",
    "zero_init_fve = [load_fve(name) for name in zero_init_names]\n",
    "random_indices_fve = [load_fve(name) for name in random_indices_names]\n",
    "random_sources_fve = [load_fve(name) for name in random_sources_names]\n",
    "full_scaler_fve = load_fve(full_scaler_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bar plot with std for one_init\n",
    "one_init_fve_mean = np.mean(one_init_fve)\n",
    "one_init_fve_std = np.std(one_init_fve)\n",
    "zero_init_fve_mean = np.mean(zero_init_fve)\n",
    "zero_init_fve_std = np.std(zero_init_fve)\n",
    "random_indices_fve_mean = np.mean(random_indices_fve)\n",
    "random_indices_fve_std = np.std(random_indices_fve)\n",
    "random_sources_fve_mean = np.mean(random_sources_fve)\n",
    "random_sources_fve_std = np.std(random_sources_fve)\n",
    "\n",
    "# Calculate relative improvements\n",
    "rel_one_init = (one_init_fve_mean - base_model_fve) / base_model_fve * 100\n",
    "rel_zero_init = (zero_init_fve_mean - base_model_fve) / base_model_fve * 100\n",
    "rel_random_indices = (random_indices_fve_mean - base_model_fve) / base_model_fve * 100\n",
    "rel_random_sources = (random_sources_fve_mean - base_model_fve) / base_model_fve * 100\n",
    "rel_full_scaler = (full_scaler_fve - base_model_fve) / base_model_fve * 100\n",
    "\n",
    "# Convert std to relative\n",
    "rel_one_init_std = one_init_fve_std / base_model_fve * 100\n",
    "rel_zero_init_std = zero_init_fve_std / base_model_fve * 100\n",
    "rel_random_indices_std = random_indices_fve_std / base_model_fve * 100\n",
    "rel_random_sources_std = random_sources_fve_std / base_model_fve * 100\n",
    "\n",
    "fig = px.bar(\n",
    "    x=[\"S_I 1-init\", \"S_I Zero Init\", \"Random Set <br> 1-init\", \"Random Vectors <br> 1-init\"],\n",
    "    y=[rel_one_init, rel_zero_init, rel_random_indices, rel_random_sources],\n",
    "    title=\"Relative FVE Improvement Over CrossCoder (%)\",\n",
    "    error_y=[rel_one_init_std, rel_zero_init_std, rel_random_indices_std, rel_random_sources_std],\n",
    ")\n",
    "\n",
    "# horizontal dashed blue line at full scaler improvement\n",
    "fig.add_hline(y=rel_full_scaler, line_dash=\"dash\", line_color=\"blue\")\n",
    "fig.update_traces(texttemplate='%{y:.2f}%', textposition='auto')\n",
    "\n",
    "# add annotation for full scaler line\n",
    "fig.add_annotation(\n",
    "    x=2,\n",
    "    y=rel_full_scaler,\n",
    "    text=\"Full Scaler Improvement\",\n",
    "    font=dict(size=16, color=\"blue\")\n",
    ")\n",
    "# Add scatter points for individual runs\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=['S_I 1-init'] * len(one_init_fve),\n",
    "    y=[(fve - base_model_fve) / base_model_fve * 100 for fve in one_init_fve],\n",
    "    mode='markers',\n",
    "    marker=dict(color='black', size=8),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=['S_I Zero Init'] * len(zero_init_fve), \n",
    "    y=[(fve - base_model_fve) / base_model_fve * 100 for fve in zero_init_fve],\n",
    "    mode='markers',\n",
    "    marker=dict(color='black', size=8),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=['Random Set <br> 1-init'] * len(random_indices_fve),\n",
    "    y=[(fve - base_model_fve) / base_model_fve * 100 for fve in random_indices_fve],\n",
    "    mode='markers', \n",
    "    marker=dict(color='black', size=8),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=['Random Vectors <br> 1-init'] * len(random_sources_fve),\n",
    "    y=[(fve - base_model_fve) / base_model_fve * 100 for fve in random_sources_fve],\n",
    "    mode='markers',\n",
    "    marker=dict(color='black', size=8),\n",
    "    showlegend=False\n",
    "))\n",
    "\n",
    "# text annotations\n",
    "# font size of 20\n",
    "fig.update_layout(font=dict(size=20), width=800, height=600)\n",
    "# axis labels\n",
    "fig.update_yaxes(title=\"Relative FVE Improvement (%)\", title_font_size=20)\n",
    "# remove x axis title\n",
    "fig.update_xaxes(title=\"\", title_font_size=20)\n",
    "min_y = min(rel_one_init, rel_zero_init, rel_random_indices, rel_random_sources, rel_full_scaler)\n",
    "max_y = max(rel_one_init, rel_zero_init, rel_random_indices, rel_random_sources, rel_full_scaler)\n",
    "fig.update_layout(yaxis_range=[min_y-0.1, max_y+0.1])\n",
    "fig.show()\n",
    "fig.write_image(PLOTS_DIR / \"scaler_fve_improvement.png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def act_func(x):\n",
    "    return th.nn.functional.elu(x) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_init_scalers = []\n",
    "for name in one_init_names:\n",
    "    scaler = th.load(CHECKPOINT_DIR / name / \"scaler_0_1.pt\", map_location=\"cpu\")\n",
    "    one_init_scalers.append(act_func(scaler[\"scaler\"]).cpu().numpy())\n",
    "one_init_scalers = np.stack(one_init_scalers)\n",
    "\n",
    "# Load all zero init scalers \n",
    "zero_init_scalers = []\n",
    "for name in zero_init_names:\n",
    "    scaler = th.load(CHECKPOINT_DIR / name / \"scaler_0_1.pt\", map_location=\"cpu\")\n",
    "    zero_init_scalers.append(act_func(scaler[\"scaler\"]).cpu().numpy())\n",
    "zero_init_scalers = np.stack(zero_init_scalers)\n",
    "\n",
    "#Â Load Random Indices and Random Sources scalers\n",
    "random_indices_scalers = []\n",
    "for name in random_indices_names:\n",
    "    scaler = th.load(CHECKPOINT_DIR / name / \"scaler_0_1.pt\", map_location=\"cpu\")\n",
    "    random_indices_scalers.append(act_func(scaler[\"scaler\"]).cpu().numpy())\n",
    "random_indices_scalers = np.stack(random_indices_scalers)\n",
    "\n",
    "random_sources_scalers = []\n",
    "for name in random_sources_names:\n",
    "    scaler = th.load(CHECKPOINT_DIR / name / \"scaler_0_1.pt\", map_location=\"cpu\")\n",
    "    random_sources_scalers.append(act_func(scaler[\"scaler\"]).cpu().numpy())\n",
    "random_sources_scalers = np.stack(random_sources_scalers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all one init scalers\n",
    "threshold = 5e-2\n",
    "\n",
    "thres_one_init = (one_init_scalers < threshold).mean(axis=1)\n",
    "thres_zero_init = (zero_init_scalers < threshold).mean(axis=1)\n",
    "thres_random_indices = (random_indices_scalers < threshold).mean(axis=1)\n",
    "thres_random_sources = (random_sources_scalers < threshold).mean(axis=1)\n",
    "\n",
    "\n",
    "one_init_mean = thres_one_init.mean() * 100\n",
    "zero_init_mean = thres_zero_init.mean() * 100\n",
    "random_indices_mean = thres_random_indices.mean() * 100\n",
    "random_sources_mean = thres_random_sources.mean() * 100\n",
    "\n",
    "one_init_std = thres_one_init.std() * 100\n",
    "zero_init_std = thres_zero_init.std() * 100\n",
    "random_indices_std = thres_random_indices.std() * 100\n",
    "random_sources_std = thres_random_sources.std() * 100\n",
    "\n",
    "# Create bar plot\n",
    "fig = px.bar(\n",
    "    x=[\"S_I 1-init\", \"S_I 0-init\", \"Random Set <br> 1-init\", \"Random Vectors <br> 1-init\"],\n",
    "    y=[one_init_mean, zero_init_mean, random_indices_mean, random_sources_mean],\n",
    "    error_y=[one_init_std, zero_init_std, random_indices_std, random_sources_std],\n",
    "    title=f\"Percentage of Dead Feature Scalars (beta_i < {threshold:.1})\",\n",
    ")\n",
    "\n",
    "# Add text annotations\n",
    "fig.update_traces(texttemplate='%{y:.1f}%', textposition='auto')\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    font=dict(size=20),\n",
    "    width=800,\n",
    "    height=600,\n",
    "    yaxis_title=\"Percentage of Dead Scalars\",\n",
    "    xaxis_title=\"\"\n",
    ")\n",
    "\n",
    "# Add min/max annotations for each bar\n",
    "y_positions = [one_init_mean, zero_init_mean, random_indices_mean, random_sources_mean]\n",
    "stds = [one_init_std, zero_init_std, random_indices_std, random_sources_std]\n",
    "x_positions = [\"1-init\", \"0-init\", \"Random Set <br> 1-init\", \"Random Vectors <br> 1-init\"]\n",
    "\n",
    "\n",
    "# Set y-axis range from 0 to slightly above max\n",
    "max_y = max(one_init_mean + one_init_std, \n",
    "            zero_init_mean + zero_init_std,\n",
    "            random_indices_mean + random_indices_std,\n",
    "            random_sources_mean + random_sources_std)\n",
    "fig.update_layout(yaxis_range=[0, max_y * 1.1])\n",
    "\n",
    "fig.show()\n",
    "fig.write_image(PLOTS_DIR / \"scaler_dead_scalars.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "# Create subplots in a 2x3 grid\n",
    "fig = make_subplots(\n",
    "    rows=2, cols=3,\n",
    "    subplot_titles=[\n",
    "        # First row: One init seed comparisons\n",
    "        f'1-init Seeds {i+1} vs {j+1}' \n",
    "        for i in range(3) \n",
    "        for j in range(i+1,3)\n",
    "    ] + [\n",
    "        # First row: One init seed comparisons\n",
    "        f'1-init Seed {i+1} vs 0-init Seed {j+1}' \n",
    "        for i in range(3) \n",
    "        for j in range(i+1,3)\n",
    "    ],\n",
    "    vertical_spacing=0.1\n",
    ")\n",
    "\n",
    "# First row: One init seed comparisons\n",
    "pairs = [(i,j) for i in range(3) for j in range(i+1,3)]\n",
    "for idx, (i,j) in enumerate(pairs):\n",
    "    # Create 2D histogram data for this pair\n",
    "    x = np.array(one_init_scalers[i]).flatten() # Ensure 1D array\n",
    "    y = np.array(one_init_scalers[j]).flatten() # Ensure 1D array\n",
    "    hist2d, x_edges, y_edges = np.histogram2d(\n",
    "        x,\n",
    "        y,\n",
    "        bins=30\n",
    "    )\n",
    "    \n",
    "    # Add heatmap to subplot\n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            x=x_edges[:-1],\n",
    "            y=y_edges[:-1], \n",
    "            z=np.log1p(hist2d.T),\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(title='Log Count'),\n",
    "            showscale=(idx==2) # only show colorbar for rightmost plot\n",
    "        ),\n",
    "        row=1, col=idx+1\n",
    "    )\n",
    "\n",
    "# Second row: One init vs Two init comparisons\n",
    "for idx, (i,j) in enumerate(pairs):\n",
    "    x = np.array(one_init_scalers[i]).flatten()\n",
    "    y = np.array(zero_init_scalers[j]).flatten()\n",
    "    hist2d, x_edges, y_edges = np.histogram2d(\n",
    "        x,\n",
    "        y,\n",
    "        bins=30\n",
    "    )\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Heatmap(\n",
    "            x=x_edges[:-1],\n",
    "            y=y_edges[:-1], \n",
    "            z=np.log1p(hist2d.T),\n",
    "            colorscale='Viridis',\n",
    "            colorbar=dict(title='Log Count'),\n",
    "            showscale=(idx==2) # only show colorbar for rightmost plot\n",
    "        ),\n",
    "        row=2, col=idx+1\n",
    "    )\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title='<b>Are the same features \"dying\"?</b> <br>2D Distributions of Feature Scaling Values',\n",
    "    width=1200,\n",
    "    height=800,\n",
    "    showlegend=False,\n",
    ")\n",
    "\n",
    "fig.write_image(PLOTS_DIR / \"scaler_2d_histo.png\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute refined feature indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.feature_utils import mask_to_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute indices of dead features\n",
    "all_scalers = np.concatenate([one_init_scalers, zero_init_scalers])\n",
    "indices = (all_scalers < 1e-4).sum(axis=0) == all_scalers.shape[0]\n",
    "# indices = mask_to_indices(th.tensor(indices))\n",
    "indices.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump indices to json\n",
    "with open(PLOTS_DIR / \"dead_feature_indices_1e-4.json\", \"w\") as f:\n",
    "    json.dump(mask_to_indices(th.tensor(indices)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute indices of dead features\n",
    "all_scalers = np.concatenate([one_init_scalers, zero_init_scalers])\n",
    "indices = (all_scalers < 1e-3).sum(axis=0) == all_scalers.shape[0]\n",
    "# indices = mask_to_indices(th.tensor(indices))\n",
    "indices.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dump indices to json\n",
    "with open(PLOTS_DIR / \"dead_feature_indices_1e-3.json\", \"w\") as f:\n",
    "    json.dump(mask_to_indices(th.tensor(indices)), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute indices of dead features\n",
    "all_scalers = np.concatenate([one_init_scalers, zero_init_scalers])\n",
    "indices = (all_scalers < 1e-2).sum(axis=0) == all_scalers.shape[0]\n",
    "# indices = mask_to_indices(th.tensor(indices))\n",
    "indices.sum()\n",
    "# dump indices to json\n",
    "with open(PLOTS_DIR / \"dead_feature_indices_1e-2.json\", \"w\") as f:\n",
    "    json.dump(mask_to_indices(th.tensor(indices)), f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create scatter plot\n",
    "fig = go.Figure(\n",
    "    data=[\n",
    "        go.Scatter(\n",
    "            x=scaled_values_one,\n",
    "            y=scaled_values_zero,\n",
    "            mode=\"markers\",\n",
    "            marker=dict(color=\"blue\", opacity=0.5),\n",
    "        )\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Update layout\n",
    "fig.update_layout(\n",
    "    title=\"Scatter Plot of Feature Scaling Values\",\n",
    "    xaxis_title=\"One Init Scaling Factor\",\n",
    "    yaxis_title=\"Zero Init Scaling Factor\",\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "default",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
